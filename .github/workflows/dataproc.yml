name: Move DAGs to GCS

on:
  push:
    branches:
      - dev
  workflow_dispatch: # Enable manual trigger

jobs:
  move-dags:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Find and Move all DAG files to Cloud Composer
        run: |
          # Find all Python files in the src/dags directory and its subdirectories
          find src/dags -type f -name "*.py" | while read -r dag_file; do
            # Extract the filename without the path
            filename=$(basename "$dag_file")
            echo "Copying $dag_file to dags/$filename"

            # Import the DAG file to Cloud Composer
            gcloud composer environments storage dags import \
              --environment test-composer-for-dataproc \
              --location us-central1 \
              --source "$dag_file" \
              --destination "dags/$filename"
          done

      - name: Move Init script to GCS
        run: |
          gcloud storage cp src/dags/init/dataproc_initialization_action.sh \
            gs://stage-yral-ds-dataproc-bucket/scripts/dataproc_initialization_action.sh
